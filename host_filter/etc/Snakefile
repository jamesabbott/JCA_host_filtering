from glob import glob
import os
import pathlib
import re
import sys
sys.path.insert(0,'/homes/jabbott/db/host_filtering')
from host_filter import genome, read_filter, analysis

envvars:
	"CONDA_PREFIX"

db=config['database']
db_obj=genome.database()
filter_obj=read_filter.read_filter()

filtered_path=Path('filtered_fastq')
db_path=Path(os.environ['CONDA_PREFIX']) / Path('share/classification_databases') 

################################################################################
#
# TARGETS 
#
################################################################################

BWA_INDEX=db_obj.get_db_index_files(db)

FASTQS=glob('*.gz',root_dir='fastq')

SAMPLES=list(set([x.split('_')[0] for x in FASTQS]))
SAMPLES.sort()

PAIR=('1','2')
STATE=('mapped','unmapped')
MPA_SUFFIX=('txt', 'bowtie2.bz2', 'biom')
KRAKEN_SUFFIX=('txt','report.txt')

KRAKEN_DB=config['kraken_db']
METAPHLAN_DB=config['metaphlan_db']

# Set MAPQ based upon type passed
if type(config.get('mapq'))==str and config.get('mapq') == 'filtered':
	# for classification jobs, run on all filtered fastq files
	MAPQ=glob('filtered_fastq/*')
	MAPQ=[x.replace('filtered_fastq/','') for x in MAPQ]
	MAPQ.remove('genome_filtered')
elif type(config.get('mapq'))==int or type(config.get('mapq'))==str or type(config.get('mapq'))==list:
	# for filtering, mapq is passed as an int, or a list for a range...
	# we can use these as they are...
	MAPQ=config.get('mapq')
else:
	MAPQ=None

READS=expand("fastq/{sample}_{pair}.fq.gz",sample=SAMPLES, pair=PAIR)
print(MAPQ)
MAPPINGS=expand("mappings/{sample}.{suffix}", sample=SAMPLES, suffix=['bam','bam.csi','flagstat']) 

FILTERED_FASTQ=expand("filtered_fastq/genome_filtered/{sample}_{state}_{pair}.fq.gz",
	sample=SAMPLES, state=STATE, pair=PAIR) + \
	expand("filtered_fastq/genome_filtered/{sample}_stats.txt", sample=SAMPLES)

MAPQ_FILTERED_FASTQ=expand("filtered_fastq/mapq_{mapq}/{sample}_{state}_{pair}.fq.gz", 
	mapq=MAPQ, sample=SAMPLES, state=STATE, pair=PAIR) + \
	expand("filtered_fastq/mapq_{mapq}/{sample}_stats.txt", mapq=MAPQ, sample=SAMPLES)

METAPHLAN=expand("metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.{suffix}", 
	metaphlan_db=METAPHLAN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE, suffix=MPA_SUFFIX) 

KRAKEN=expand("kraken/{kraken_db}/mapq_{mapq}/{sample}_{state}.{suffix}", 
	kraken_db=KRAKEN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE, suffix=KRAKEN_SUFFIX) 

KRAKEN_UNFILTERED=expand("kraken/{kraken_db}/unfiltered/{sample}_unfiltered.{suffix}",
	kraken_db=KRAKEN_DB, sample=SAMPLES, suffix=KRAKEN_SUFFIX)

KRAKEN_GENOME_FILTERED=expand("kraken/{kraken_db}/genome_filtered/{sample}_{state}.{suffix}",
	kraken_db=KRAKEN_DB, sample=SAMPLES, state=STATE, suffix=KRAKEN_SUFFIX)

KRAKEN_BIOM=expand("kraken/{kraken_db}/biom/{mapq}.biom", 
	kraken_db=KRAKEN_DB, mapq=MAPQ, state=STATE) + expand("kraken/{kraken_db}/biom/unfiltered.biom", kraken_db=KRAKEN_DB)

################################################################################
#
# RULES
#
################################################################################

ruleorder: classify_kraken_genome_filtered > classify_kraken

rule mappings:
	input: FILTERED_FASTQ 

rule mapq_filter:
	input: MAPQ_FILTERED_FASTQ

rule metaphlan:
	input: METAPHLAN

rule kraken:
	input: KRAKEN_GENOME_FILTERED + KRAKEN_BIOM

rule map:
	message: "Mapping sample {wildcards.sample} with BWA..."
	input:
		R1 = "fastq/{sample}_1.fq.gz",
		R2 = "fastq/{sample}_2.fq.gz",
		INDEX = BWA_INDEX
	output:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi",
		flagstat = "mappings/{sample}.flagstat"
	params:
		bwa_index_name=BWA_INDEX[0].replace('.amb','')
	log: "logs/map.{sample}.log"
	shadow: config['shadow']
	threads: config['threads'] 
	conda: "map.yaml"
	shell: """
echo Hostname=$HOSTNAME
bwa mem -t {threads} -M {params.bwa_index_name} {input.R1} {input.R2} 2> {log} \
  | samtools sort -@ {threads} --write-index -o mappings/{wildcards.sample}.bam -
samtools flagstat mappings/{wildcards.sample}.bam > mappings/{wildcards.sample}.flagstat
"""

rule separate_mapped:
	message: "Splitting {wildcards.sample} mapped reads to filtered/unfiltered fastq files"
	input: 
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi",
		flagstat = "mappings/{sample}.flagstat"
	output:
		r1 = "filtered_fastq/genome_filtered/{sample}_unmapped_1.fq.gz", 
		r2 = "filtered_fastq/genome_filtered/{sample}_unmapped_2.fq.gz",
		r3 = "filtered_fastq/genome_filtered/{sample}_mapped_1.fq.gz",
		r4 = "filtered_fastq/genome_filtered/{sample}_mapped_2.fq.gz",
		stats = "filtered_fastq/genome_filtered/{sample}_stats.txt",
	log: "logs/filter_{sample}_genome_filtered"
	shadow: config['shadow']
	threads: 4
	shell: """
	samtools fastq -@ 4 -f 12 -1 {output.r1} -2 {output.r2} {input.bam}
	samtools fastq -@ 4 -f 3 -1 {output.r3} -2 {output.r4} {input.bam}
	mapped_lines=$(zcat {output.r3}|wc -l)
	unmapped_lines=$(zcat {output.r1}|wc -l)
	mapped_count=$(($mapped_lines/4))
	unmapped_count=$(($unmapped_lines/4))
	echo -e "Mapped\t$mapped_count" > {output.stats}
	echo -e "Unmapped\t$unmapped_count" >> {output.stats}
	"""

rule read_mapq_filter:
	message: "Filtering {wildcards.sample} mappings to MAPQ {wildcards.mapq}..."
	input:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi"
	output: 
		r1 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_1.fq.gz", 
		r2 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_2.fq.gz",
		r3 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_1.fq.gz",
		r4 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_2.fq.gz",
		stats = "filtered_fastq/mapq_{mapq}/{sample}_stats.txt",
	log: "logs/filter_{sample}_{mapq}.log"
	shadow: config['shadow']
	threads: 1
	run:
		filter_obj.mapq_filter(int(wildcards.mapq), wildcards.sample)
		

rule classify_metaphlan:
	message: "Classifying {wildcards.sample} with metaphlan against {wildcards.metaphlan_db}..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		biom = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.biom",
		bz2 = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.bowtie2.bz2",
		txt = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.txt"
	params:
		db_path=db_path
	log: "logs/metaphlan_{metaphlan_db}_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "metaphlan.yaml"
	shell:"""
metaphlan {input.r1},{input.r2} --input_type fastq \
	--bowtie2out metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.bowtie2.bz2 \
	-o metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt \
	--biom metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.biom --nproc {threads} \
	--bowtie2db {params.db_path}/{wildcards.metaphlan_db}
"""

rule classify_kraken:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		txt = "kraken/{kraken_db}/{mapq}/{sample}_{state}.txt",
		report = "kraken/{kraken_db}/{mapq}/{sample}_{state}.report.txt"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.report.txt \
		--output kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt --gzip-compressed --paired {input.r1} {input.r2}
"""

rule classify_kraken_unfiltered:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "fastq/{sample}_1.fq.gz",
		r2 = "fastq/{sample}_2.fq.gz"
	output: 
		txt = "kraken/{kraken_db}/unfiltered/{sample}_unfiltered.txt",
		report = "kraken/{kraken_db}/unfiltered/{sample}_unfiltered.report.txt"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_unfiltered_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/unfiltered/{wildcards.sample}_unfiltered.report.txt \
		--output kraken/{wildcards.kraken_db}/unfiltered/{wildcards.sample}_unfiltered.txt --gzip-compressed --paired {input.r1} {input.r2}
"""

rule classify_kraken_genome_filtered:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "filtered_fastq/genome_filtered/{sample}_unmapped_1.fq.gz", 
		r2 = "filtered_fastq/genome_filtered/{sample}_unmapped_2.fq.gz",
		r3 = "filtered_fastq/genome_filtered/{sample}_mapped_1.fq.gz",
		r4 = "filtered_fastq/genome_filtered/{sample}_mapped_2.fq.gz",
	output: 
		mapped_txt = "kraken/{kraken_db}/genome_filtered/{sample}_mapped.txt",
		mapped_report = "kraken/{kraken_db}/genome_filtered/{sample}_mapped.report.txt",
		unmapped_txt = "kraken/{kraken_db}/genome_filtered/{sample}_unmapped.txt",
		unmapped_report = "kraken/{kraken_db}/genome_filtered/{sample}_unmapped.report.txt"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_genome_filtered_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/genome_filtered/{wildcards.sample}_unmapped.report.txt \
		--output kraken/{wildcards.kraken_db}/genome_filtered/{wildcards.sample}_unmapped.txt --gzip-compressed --paired {input.r1} {input.r2}
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/genome_filtered/{wildcards.sample}_mapped.report.txt \
		--output kraken/{wildcards.kraken_db}/genome_filtered/{wildcards.sample}_mapped.txt --gzip-compressed --paired {input.r3} {input.r4}
"""

rule kraken_biom:
	input: expand("kraken/{kraken_db}/{mapq}/{sample}_{state}.report.txt", kraken_db=KRAKEN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE) + 
			expand("kraken/{kraken_db}/unfiltered/{sample}_unfiltered.report.txt", kraken_db=KRAKEN_DB, sample=SAMPLES) +
			expand("kraken/{kraken_db}/genome_filtered/{sample}_{state}.report.txt", kraken_db=KRAKEN_DB, sample=SAMPLES, state=STATE)
	output: expand("kraken/{kraken_db}/biom/{mapq}.biom",kraken_db=KRAKEN_DB, mapq=MAPQ) + \
			expand("kraken/{kraken_db}/biom/unfiltered.biom", kraken_db=KRAKEN_DB) + \
			expand("kraken/{kraken_db}/biom/mapped.biom", kraken_db=KRAKEN_DB) + \
			expand("kraken/{kraken_db}/biom/unmapped.biom", kraken_db=KRAKEN_DB)

	params:
		kraken_db=KRAKEN_DB
	shadow: config['shadow']
	threads: 1
	conda: "kraken.yaml"
	shell:"""
	for mapq_dir in $(ls kraken/{params.kraken_db}|grep mapq); do
			mapq=$(basename ${{mapq_dir}}|sed 's/mapq_//')
			files=$(ls kraken/{params.kraken_db}/${{mapq_dir}}/*.report.txt)
			for file in ${{files[@]}}; do
				new=$(basename $file|sed "s/report/$mapq/")
				cp $file $TMPDIR/$new
			done
			files=$(ls $TMPDIR/*txt)
			echo $mapq: ${{files[@]}}
			kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/${{mapq_dir}}.biom ${{files[@]}} 
			ls -l kraken/{params.kraken_db}/biom
			rm $TMPDIR/*
	done

	unfiltered_files=$(ls kraken/{params.kraken_db}/unfiltered/*.report.txt)
	for file in ${{unfiltered_files[@]}}; do
		new=$(basename $file|sed 's/report//')
		cp $file $TMPDIR/$new
	done
	unfiltered_files=$(ls $TMPDIR/*txt)
	echo unfiltered: ${{unfiltered_files[@]}}
	kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/unfiltered.biom ${{unfiltered_files[@]}}
	ls -l kraken/{params.kraken_db}/biom

	rm $TMPDIR/*txt
	unmapped_files=$(ls kraken/{params.kraken_db}/genome_filtered/*_unmapped.report.txt)
	for file in ${{unmapped_files[@]}}; do
		new=$(basename $file|sed 's/report//')
		cp $file $TMPDIR/$new
	done
	unmapped_files=$(ls $TMPDIR/*txt)
	echo unmapped: ${{unmapped_files[@]}}
	kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/unmapped.biom ${{unmapped_files[@]}}
	ls -l kraken/{params.kraken_db}/biom

	rm $TMPDIR/*txt
	mapped_files=$(ls kraken/{params.kraken_db}/genome_filtered/*_mapped.report.txt)
	for file in ${{mapped_files[@]}}; do
		new=$(basename $file|sed 's/report//')
		cp $file $TMPDIR/$new
	done
	mapped_files=$(ls $TMPDIR/*txt)
	echo mapped: ${{mapped_files[@]}}
	kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/mapped.biom ${{mapped_files[@]}}
	ls -l kraken/{params.kraken_db}/biom
"""