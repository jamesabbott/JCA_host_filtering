from glob import glob
import os
import pathlib
import re
import sys
sys.path.insert(0,'/homes/jabbott/db/host_filtering')
from host_filter import genome, read_filter, analysis

envvars:
	"CONDA_PREFIX"

db=config['database']
db_obj=genome.database()
filter_obj=read_filter.read_filter()

filtered_path=Path('filtered_fastq')
db_path=Path(os.environ['CONDA_PREFIX']) / Path('share/classification_databases') 

################################################################################
#
# TARGETS 
#
################################################################################

BWA_INDEX=db_obj.get_db_index_files(db)

FASTQS=glob('*.gz',root_dir='fastq')

SAMPLES=list(set([x.split('_')[0] for x in FASTQS]))
SAMPLES.sort()

PAIR=('1','2')
STATE=('mapped','unmapped')
MPA_SUFFIX=('txt', 'bowtie2.bz2', 'biom')
KRAKEN_SUFFIX=('txt','report.txt')

KRAKEN_DB=config['kraken_db']
METAPHLAN_DB=config['metaphlan_db']

# Set MAPQ based upon type passed
if type(config.get('mapq'))==str and config.get('mapq') == 'filtered':
	# for classification jobs, run on all filtered fastq files
	MAPQ=glob('filtered_fastq/*')
	MAPQ=[x.replace('filtered_fastq/','') for x in MAPQ]
elif type(config.get('mapq'))==int or type(config.get('mapq'))==str or type(config.get('mapq'))==list:
	# for filtering, mapq is passed as an int, or a list for a range...
	# we can use these as they are...
	MAPQ=config.get('mapq')
else:
	# otherwise, we don't need MAPQ (mapping...)
	MAPQ=None

READS=expand("fastq/{sample}_{pair}.fq.gz",sample=SAMPLES, pair=PAIR)

MAPPINGS=expand("mappings/{sample}.{suffix}", sample=SAMPLES, suffix=['bam','bam.csi','flagstat']) 

MAPQ_FILTERED_FASTQ=expand("filtered_fastq/mapq_{mapq}/{sample}_{state}_{pair}.fq.gz", 
	mapq=MAPQ, sample=SAMPLES, state=STATE, pair=PAIR) + \
	expand("filtered_fastq/mapq_{mapq}/{sample}_stats.txt", mapq=MAPQ, sample=SAMPLES)

METAPHLAN=expand("metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.{suffix}", 
	metaphlan_db=METAPHLAN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE, suffix=MPA_SUFFIX) 

KRAKEN=expand("kraken/{kraken_db}/mapq_{mapq}/{sample}_{state}.{suffix}", 
	kraken_db=KRAKEN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE, suffix=KRAKEN_SUFFIX) 

KRAKEN_UNFILTERED=expand("kraken/{kraken_db}/unfiltered/{sample}_unfiltered.{suffix}",
	kraken_db=KRAKEN_DB, sample=SAMPLES, suffix=KRAKEN_SUFFIX)

KRAKEN_BIOM=expand("kraken/{kraken_db}/biom/{mapq}.biom", 
	kraken_db=KRAKEN_DB, mapq=MAPQ, state=STATE) + expand("kraken/{kraken_db}/biom/unfiltered.biom", kraken_db=KRAKEN_DB)

################################################################################
#
# RULES
#
################################################################################

rule mappings:
	input: MAPPINGS

rule mapq_filter:
	input: MAPQ_FILTERED_FASTQ

rule metaphlan:
	input: METAPHLAN

rule kraken:
	input: KRAKEN_BIOM

rule map:
	message: "Mapping sample {wildcards.sample} with BWA..."
	input:
		R1 = "fastq/{sample}_1.fq.gz",
		R2 = "fastq/{sample}_2.fq.gz",
		INDEX = BWA_INDEX
	output:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi",
		flagstat = "mappings/{sample}.flagstat"
	params:
		bwa_index_name=BWA_INDEX[0].replace('.amb','')
	log: "logs/map.{sample}.log"
	shadow: config['shadow']
	threads: config['threads'] 
	conda: "map.yaml"
	shell: """
echo Hostname=$HOSTNAME
bwa mem -t {threads} -M {params.bwa_index_name} {input.R1} {input.R2} 2> {log} \
  | samtools sort -@ {threads} --write-index -o mappings/{wildcards.sample}.bam -
samtools flagstat mappings/{wildcards.sample}.bam > mappings/{wildcards.sample}.flagstat
"""

rule read_mapq_filter:
	message: "Filtering {wildcards.sample} mappings to MAPQ {wildcards.mapq}..."
	input:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi"
	output: 
		r1 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_1.fq.gz", 
		r2 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_2.fq.gz",
		r3 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_1.fq.gz",
		r4 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_2.fq.gz",
		stats = "filtered_fastq/mapq_{mapq}/{sample}_stats.txt",
	log: "logs/filter_{sample}_{mapq}.log"
	shadow: config['shadow']
	threads: 1
	run:
		filter_obj.mapq_filter(int(wildcards.mapq), wildcards.sample)
		

rule classify_metaphlan:
	message: "Classifying {wildcards.sample} with metaphlan against {wildcards.metaphlan_db}..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		biom = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.biom",
		bz2 = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.bowtie2.bz2",
		txt = "metaphlan/{metaphlan_db}/{mapq}/{sample}_{state}.txt"
	params:
		db_path=db_path
	log: "logs/metaphlan_{metaphlan_db}_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "metaphlan.yaml"
	shell:"""
metaphlan {input.r1},{input.r2} --input_type fastq \
	--bowtie2out metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.bowtie2.bz2 \
	-o metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt \
	--biom metaphlan/{wildcards.metaphlan_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.biom --nproc {threads} \
	--bowtie2db {params.db_path}/{wildcards.metaphlan_db}
"""

rule classify_kraken:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		txt = "kraken/{kraken_db}/{mapq}/{sample}_{state}.txt",
		report = "kraken/{kraken_db}/{mapq}/{sample}_{state}.report.txt"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.report.txt \
		--output kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt --gzip-compressed --paired {input.r1} {input.r2}
"""

rule classify_kraken_unfiltered:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "fastq/{sample}_1.fq.gz",
		r2 = "fastq/{sample}_2.fq.gz"
	output: 
		txt = "kraken/{kraken_db}/unfiltered/{sample}_unfiltered.txt",
		report = "kraken/{kraken_db}/unfiltered/{sample}_unfiltered.report.txt"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_unfiltered_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/unfiltered/{wildcards.sample}_unfiltered.report.txt \
		--output kraken/{wildcards.kraken_db}/unfiltered/{wildcards.sample}_unfiltered.txt --gzip-compressed --paired {input.r1} {input.r2}
"""

rule kraken_biom:
	input: expand("kraken/{kraken_db}/{mapq}/{sample}_{state}.report.txt", kraken_db=KRAKEN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE) + 
			expand("kraken/{kraken_db}/unfiltered/{sample}_unfiltered.report.txt", kraken_db=KRAKEN_DB, sample=SAMPLES)
	output: expand("kraken/{kraken_db}/biom/{mapq}.biom",kraken_db=KRAKEN_DB, mapq=MAPQ) + \
			expand("kraken/{kraken_db}/biom/unfiltered.biom", kraken_db=KRAKEN_DB)
	params:
		kraken_db=KRAKEN_DB
	shadow: config['shadow']
	threads: 1
	conda: "kraken.yaml"
	shell:"""
	for mapq_dir in $(ls kraken/{params.kraken_db}|grep mapq); do
			mapq=$(basename ${{mapq_dir}}|sed 's/mapq_//')
			files=$(ls kraken/{params.kraken_db}/${{mapq_dir}}/*.report.txt)
			for file in ${{files[@]}}; do
				new=$(basename $file|sed "s/report/$mapq/")
				cp $file $TMPDIR/$new
			done
			files=$(ls $TMPDIR/*txt)
			echo ${{files[@]}}
			kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/${{mapq_dir}}.biom ${{files[@]}} 
	done
	rm $TMPDIR/*txt
	unfiltered_files=$(ls kraken/{params.kraken_db}/unfiltered/*.report.txt)
	for file in ${{unfiltered_files[@]}}; do
		new=$(basename $file|sed 's/report/unfiltered/')
		cp $file $TMPDIR/$new
	done
	unfiltered_files=$(ls $TMPDIR/*txt)
	kraken-biom --fmt json -o kraken/{params.kraken_db}/biom/unfiltered.biom ${{unfiltered_files[@]}}
"""