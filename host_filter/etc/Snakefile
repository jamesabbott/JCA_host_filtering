from glob import glob
import os
import pathlib
import re
import sys
sys.path.insert(0,'/homes/jabbott/db/host_filtering')
from host_filter import genome, read_filter

envvars:
	"CONDA_PREFIX"

db=config['database']
db_obj=genome.database()
filter_obj=read_filter.read_filter()

filtered_path=Path('filtered_fastq')
db_path=Path(os.environ['CONDA_PREFIX']) / Path('share/classification_databases') 

################################################################################
#
# TARGETS 
#
################################################################################

BWA_INDEX=db_obj.get_db_index_files(db)

FASTQS=glob('*.gz',root_dir='fastq')

SAMPLES=list(set([x.split('_')[0] for x in FASTQS]))
SAMPLES.sort()

PAIR=('1','2')
STATE=('mapped','unmapped')
MPA_SUFFIX=('txt', 'bowtie2.bz2', 'biom')
KRAKEN_SUFFIX=('txt','report.txt', 'biom')

KRAKEN_DB=config['kraken_db']

# Set MAPQ based upon type passed
if type(config.get('mapq'))==str and config.get('mapq') == 'filtered':
	# for classification jobs, run on all filtered fastq files
	MAPQ=glob('filtered_fastq/*')
	MAPQ=[x.replace('filtered_fastq/','') for x in MAPQ]
elif type(config.get('mapq'))==int or type(config.get('mapq'))==list:
	# for filtering, mapq is passed as an int, or a list for a range...
	# we can use these as they are...
	MAPQ=config.get('mapq')
else:
	# otherwise, we don't need MAPQ (mapping...)
	MAPQ=None

READS=expand("fastq/{sample}_{pair}.fq.gz",sample=SAMPLES, pair=PAIR)

MAPPINGS=expand("mappings/{sample}.bam",sample=SAMPLES) + \
		 expand("mappings/{sample}.bam.csi",sample=SAMPLES)

MAPQ_FILTERED_FASTQ=expand("filtered_fastq/mapq_{mapq}/{sample}_{state}_{pair}.fq.gz", 
	mapq=MAPQ, sample=SAMPLES, state=STATE, pair=PAIR)

METAPHLAN=expand("metaphlan/{mapq}/{sample}_{state}.{suffix}", 
	mapq=MAPQ, sample=SAMPLES, state=STATE,suffix=MPA_SUFFIX) 

KRAKEN=expand("kraken/{kraken_db}/{mapq}/{sample}_{state}.{suffix}", 
	kraken_db=KRAKEN_DB, mapq=MAPQ, sample=SAMPLES, state=STATE,suffix=KRAKEN_SUFFIX) 

################################################################################
#
# RULES
#
################################################################################

rule mappings:
	input: MAPPINGS

rule mapq_filter:
	input: MAPQ_FILTERED_FASTQ

rule metaphlan:
	input: METAPHLAN

rule kraken:
	input: KRAKEN

rule map:
	message: "Mapping sample {wildcards.sample} with BWA..."
	input:
		R1 = "fastq/{sample}_1.fq.gz",
		R2 = "fastq/{sample}_2.fq.gz",
		INDEX = BWA_INDEX
	output:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi"
	params:
		bwa_index_name=BWA_INDEX[0].replace('.amb','')
	log: "logs/map.{sample}.log"
	shadow: config['shadow']
	threads: config['threads'] 
	conda: "map.yaml"
	shell: """
echo Hostname=$HOSTNAME
bwa mem -t {threads} -M {params.bwa_index_name} {input.R1} {input.R2} 2> {log} \
  | samtools sort -@ {threads} --write-index -o mappings/{wildcards.sample}.bam -
"""

rule read_mapq_filter:
	message: "Filtering {wildcards.sample} mappings to MAPQ {wildcards.mapq}..."
	input:
		bam   = "mappings/{sample}.bam",
		index = "mappings/{sample}.bam.csi"
	output: 
		r1 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_1.fq.gz", 
		r2 = "filtered_fastq/mapq_{mapq}/{sample}_unmapped_2.fq.gz",
		r3 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_1.fq.gz",
		r4 = "filtered_fastq/mapq_{mapq}/{sample}_mapped_2.fq.gz"
	log: "logs/filter_{sample}_{mapq}.log"
	shadow: config['shadow']
	threads: 1
	run:
		filter_obj.mapq_filter(int(wildcards.mapq), wildcards.sample)
		

rule classify_metaphlan:
	message: "Classifying {wildcards.sample} with metaphlan..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		biom = "metaphlan/{mapq}/{sample}_{state}.biom",
		bz2 = "metaphlan/{mapq}/{sample}_{state}.bowtie2.bz2",
		txt = "metaphlan/{mapq}/{sample}_{state}.txt"
	params:
		db_path=db_path
	log: "logs/metaphlan_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "metaphlan.yaml"
	shell:"""
metaphlan {input.r1},{input.r2} --input_type fastq --bowtie2out metaphlan/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.bowtie2.bz2 \
	-o metaphlan/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt --biom metaphlan/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.biom --nproc {threads} \
	--bowtie2db {params.db_path}/metaphlan
"""

rule classify_kraken:
	message: "Classifying {wildcards.sample} with kraken against {wildcards.kraken_db}..."
	input:
		r1 = "filtered_fastq/{mapq}/{sample}_{state}_1.fq.gz",
		r2 = "filtered_fastq/{mapq}/{sample}_{state}_2.fq.gz"
	output: 
		txt = "kraken/{kraken_db}/{mapq}/{sample}_{state}.txt",
		report = "kraken/{kraken_db}/{mapq}/{sample}_{state}.report.txt",
		biom = "kraken/{kraken_db}/{mapq}/{sample}_{state}.biom"
	params:
		db_path=f"{db_path}/{config['kraken_db']}"
	log: "logs/kraken_{kraken_db}_{mapq}_{state}_{sample}.log"
	shadow: config['shadow']
	threads: 16
	conda: "kraken.yaml"
	shell:"""
kraken2 --db {params.db_path} --threads {threads} --use-names --report kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.report.txt \
		--output kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.txt --gzip-compressed --paired {input.r1} {input.r2}
kraken-biom --fmt json -o kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.biom \
		kraken/{wildcards.kraken_db}/{wildcards.mapq}/{wildcards.sample}_{wildcards.state}.report.txt
"""
